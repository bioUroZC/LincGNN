{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bb7f3b",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce7403",
   "metadata": {},
   "source": [
    "### GNN Link Prediction Workflow\n",
    "\n",
    "#### 1. Data Preparation\n",
    "- [ ] Obtain dataset (e.g., Cora, CiteSeer)\n",
    "- [ ] Preprocess data:\n",
    "  - [ ] Normalize node features\n",
    "  - [ ] Convert to undirected graph (if needed)\n",
    "- [x] Split edges:\n",
    "  - [x] Training set (80%)\n",
    "  - [x] Validation set (10%)\n",
    "  - [x] Test set (10%)\n",
    "- [x] Generate negative samples:\n",
    "  - [ ] Validation negatives (1:1 ratio)\n",
    "  - [ ] Test negatives (1:1 ratio)\n",
    "\n",
    "#### 2. Model Architecture\n",
    "- [ ] Implement GNN encoder:\n",
    "  - [ ] Choose layer type (GCN/GraphSAGE)\n",
    "  - [ ] 2-layer architecture\n",
    "  - [ ] ReLU activation\n",
    "- [ ] Implement decoder:\n",
    "  - [ ] Dot product scorer\n",
    "  - [ ] Sigmoid activation\n",
    "\n",
    "#### 3. Training Setup\n",
    "- [ ] Initialize optimizer (Adam)\n",
    "- [ ] Set learning rate (~0.01)\n",
    "- [ ] Define loss function (BCE)\n",
    "- [ ] Implement negative sampling:\n",
    "  - [ ] Dynamic per-epoch sampling\n",
    "  - [ ] 1:1 positive:negative ratio\n",
    "\n",
    "#### 4. Evaluation Metrics\n",
    "- [ ] AUC-ROC calculation\n",
    "- [ ] Accuracy/F1-score\n",
    "- [ ] Precision-Recall curve\n",
    "\n",
    "#### 5. PyTorch Implementation\n",
    "- [ ] Environment setup:\n",
    "  ```bash\n",
    "  pip install torch torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cea73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446cc2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 3322\n",
      "Number of edges: 10747\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "class LinkPredictionDataset(Dataset):\n",
    "    def __init__(self, net_csv_path, label_csv_path, transform=None):\n",
    "        super().__init__(transform=transform)\n",
    "        \n",
    "        # Load data\n",
    "        self.net_df = pd.read_excel(net_csv_path)\n",
    "        self.label_df = pd.read_excel(label_csv_path)\n",
    "        \n",
    "        # Create node mappings\n",
    "        all_nodes = set(self.net_df['Regulator']).union(set(self.net_df['Target']))\n",
    "        self.node_to_idx = {node: idx for idx, node in enumerate(all_nodes)}\n",
    "        self.idx_to_node = {idx: node for node, idx in self.node_to_idx.items()}\n",
    "        \n",
    "        # Create edge index from network data\n",
    "        regulators = [self.node_to_idx[reg] for reg in self.net_df['Regulator']]\n",
    "        targets = [self.node_to_idx[target] for target in self.net_df['Target']]\n",
    "        self.edge_index = torch.tensor([regulators, targets], dtype=torch.long)\n",
    "        \n",
    "        # Create simple node features (just identity matrix for now)\n",
    "        self.num_nodes = len(all_nodes)\n",
    "        self.x = torch.eye(self.num_nodes, dtype=torch.float)\n",
    "        \n",
    "        # Prepare labels for link prediction (binary: edge exists or not)\n",
    "        self.edge_labels = torch.ones(len(regulators), dtype=torch.float)\n",
    "        \n",
    "    def len(self):\n",
    "        return 1  # Single graph for link prediction\n",
    "    \n",
    "    def get(self, idx):\n",
    "        # Return the graph data\n",
    "        data = Data(\n",
    "            x=self.x,\n",
    "            edge_index=self.edge_index,\n",
    "            edge_attr=self.edge_labels,\n",
    "            num_nodes=self.num_nodes\n",
    "        )\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return data\n",
    "\n",
    "# Usage example:\n",
    "dataset = LinkPredictionDataset('data/net.xlsx', 'data/label.xlsx')\n",
    "data = dataset[0]  # Get the graph\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.edge_index.size(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6727432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Network Data:\n",
      "   Unnamed: 0  Regulator      Target RegulatorType TargetType  \\\n",
      "0           1      NEAT1  miR-194-5p        lncRNA      miRNA   \n",
      "1           2  LINC00460     miR-206        lncRNA      miRNA   \n",
      "2           3     MALAT1     miR-497        lncRNA      miRNA   \n",
      "3           4       MIAT     miR-29b        lncRNA      miRNA   \n",
      "4           5      CASC7     miR-30c        lncRNA      miRNA   \n",
      "\n",
      "  regulatory_Mechanism  \n",
      "0      ceRNA or sponge  \n",
      "1      ceRNA or sponge  \n",
      "2      ceRNA or sponge  \n",
      "3      ceRNA or sponge  \n",
      "4      ceRNA or sponge  \n",
      "\n",
      "Sample Label Data:\n",
      "   Unnamed: 0      Regulator  cell.proliferation  cell.invasion  \\\n",
      "0           1  1700020I14Rik                   0              0   \n",
      "1           2            7SK                   1              0   \n",
      "2           3            91H                   0              1   \n",
      "3           4        A2M-AS1                   1              1   \n",
      "4           5          AATBC                   1              0   \n",
      "\n",
      "   cell.migration  apoptosis.process  \n",
      "0               0                  1  \n",
      "1               0                  0  \n",
      "2               1                  0  \n",
      "3               1                  1  \n",
      "4               0                  1  \n",
      "\n",
      "Processed PyG Data Object:\n",
      "Node features shape: torch.Size([3322, 3322])\n",
      "Edge index shape: torch.Size([2, 10747])\n",
      "First few edges (source -> target):\n",
      "  NEAT1 -> miR-194-5p\n",
      "  LINC00460 -> miR-206\n",
      "  MALAT1 -> miR-497\n",
      "  MIAT -> miR-29b\n",
      "  CASC7 -> miR-30c\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 143\u001b[0m\n\u001b[1;32m    141\u001b[0m dataset \u001b[38;5;241m=\u001b[39m LinkPredictionDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/net.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/label.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m print_sample_data(dataset)\n\u001b[0;32m--> 143\u001b[0m \u001b[43mvisualize_graph_plotly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Interactive Plotly version\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mvisualize_graph_plotly\u001b[0;34m(dataset, width, height)\u001b[0m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create NetworkX graph\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241m.\u001b[39mGraph()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Add nodes with labels\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, node_name \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39midx_to_node\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "def visualize_graph_plotly(dataset, width=800, height=600):\n",
    "    \"\"\"\n",
    "    Create an interactive Plotly visualization of the graph\n",
    "    \"\"\"\n",
    "    data = dataset[0]\n",
    "    \n",
    "    # Create NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes with labels\n",
    "    for idx, node_name in dataset.idx_to_node.items():\n",
    "        G.add_node(idx, label=node_name)\n",
    "    \n",
    "    # Add edges\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    edges = [(edge_index[0][i], edge_index[1][i]) for i in range(edge_index.shape[1])]\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # Generate layout\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "    \n",
    "    # Determine node types and colors\n",
    "    node_types = {}\n",
    "    for _, row in dataset.net_df.iterrows():\n",
    "        regulator = row['Regulator']\n",
    "        target = row['Target']\n",
    "        reg_type = row['RegulatorType']\n",
    "        target_type = row['TargetType']\n",
    "        \n",
    "        if regulator in dataset.node_to_idx:\n",
    "            node_types[dataset.node_to_idx[regulator]] = reg_type\n",
    "        if target in dataset.node_to_idx:\n",
    "            node_types[dataset.node_to_idx[target]] = target_type\n",
    "    \n",
    "    # Prepare edge traces\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "    \n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=1, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    # Prepare node traces by type\n",
    "    color_map = {'lncRNA': '#1f77b4', 'miRNA': '#ff7f0e', 'mRNA': '#2ca02c'}\n",
    "    node_traces = []\n",
    "    \n",
    "    for node_type, color in color_map.items():\n",
    "        # Filter nodes by type\n",
    "        node_indices = [idx for idx, ntype in node_types.items() if ntype == node_type]\n",
    "        \n",
    "        if node_indices:\n",
    "            node_x = [pos[idx][0] for idx in node_indices]\n",
    "            node_y = [pos[idx][1] for idx in node_indices]\n",
    "            node_labels = [dataset.idx_to_node[idx] for idx in node_indices]\n",
    "            \n",
    "            node_trace = go.Scatter(\n",
    "                x=node_x, y=node_y,\n",
    "                mode='markers+text',\n",
    "                text=node_labels,\n",
    "                textposition=\"middle center\",\n",
    "                textfont=dict(size=10, color='white'),\n",
    "                hoverinfo='text',\n",
    "                hovertext=[f\"{label}<br>Type: {node_type}\" for label in node_labels],\n",
    "                marker=dict(\n",
    "                    size=20,\n",
    "                    color=color,\n",
    "                    line=dict(width=2, color='white')\n",
    "                ),\n",
    "                name=node_type\n",
    "            )\n",
    "            node_traces.append(node_trace)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[edge_trace] + node_traces,\n",
    "                   layout=go.Layout(\n",
    "                        title=dict(\n",
    "                            text='Interactive Regulatory Network Graph',\n",
    "                            x=0.5,\n",
    "                            font=dict(size=16)\n",
    "                        ),\n",
    "                        showlegend=True,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20,l=5,r=5,t=40),\n",
    "                        annotations=[ dict(\n",
    "                            text=\"Hover over nodes for details. Use mouse to zoom and pan.\",\n",
    "                            showarrow=False,\n",
    "                            xref=\"paper\", yref=\"paper\",\n",
    "                            x=0.005, y=-0.002,\n",
    "                            xanchor=\"left\", yanchor=\"bottom\",\n",
    "                            font=dict(color=\"#888\", size=12)\n",
    "                        )],\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        width=width,\n",
    "                        height=height,\n",
    "                        plot_bgcolor='white'\n",
    "                        ))\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Interactive Graph Created!\")\n",
    "    print(f\"Number of nodes: {data.num_nodes}\")\n",
    "    print(f\"Number of edges: {data.edge_index.size(1)}\")\n",
    "    print(f\"Node types: {list(color_map.keys())}\")\n",
    "    print(\"Features: Zoom, pan, hover for details, toggle node types in legend\")\n",
    "\n",
    "def print_sample_data(dataset):\n",
    "    \"\"\"\n",
    "    Print sample of the original data and processed tensors\n",
    "    \"\"\"\n",
    "    print(\"Sample Network Data:\")\n",
    "    print(dataset.net_df.head())\n",
    "    print(\"\\nSample Label Data:\")\n",
    "    print(dataset.label_df.head())\n",
    "    \n",
    "    data = dataset[0]\n",
    "    print(f\"\\nProcessed PyG Data Object:\")\n",
    "    print(f\"Node features shape: {data.x.shape}\")\n",
    "    print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "    print(f\"First few edges (source -> target):\")\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    for i in range(min(5, edge_index.shape[1])):\n",
    "        source_name = dataset.idx_to_node[edge_index[0][i]]\n",
    "        target_name = dataset.idx_to_node[edge_index[1][i]]\n",
    "        print(f\"  {source_name} -> {target_name}\")\n",
    "\n",
    "# Example usage (uncomment when you have the CSV files):\n",
    "dataset = LinkPredictionDataset('data/net.xlsx', 'data/label.xlsx')\n",
    "print_sample_data(dataset)\n",
    "visualize_graph_plotly(dataset)  # Interactive Plotly version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf578ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3322, 3322], edge_index=[2, 8858], edge_attr=[8858], num_nodes=3322, edge_label=[8858], edge_label_index=[2, 8858])\n",
      "Data(x=[3322, 3322], edge_index=[2, 8858], edge_attr=[8858], num_nodes=3322, edge_label=[1106], edge_label_index=[2, 1106])\n",
      "Data(x=[3322, 3322], edge_index=[2, 9964], edge_attr=[9964], num_nodes=3322, edge_label=[1106], edge_label_index=[2, 1106])\n"
     ]
    }
   ],
   "source": [
    "## split into test val train\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# Apply the transform to your data object\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1, num_test=0.1,  # 10% val, 10% test\n",
    "    is_undirected=True,         # Set to True if your graph is undirected\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1.0      # 1:1 positive:negative\n",
    ")\n",
    "\n",
    "data = dataset[0]\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "207e4ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 0.6931 | Val AUC: 0.8626 | Val F1: 0.6667\n",
      "Epoch 010 | Loss: 0.5889 | Val AUC: 0.8328 | Val F1: 0.6667\n",
      "Epoch 020 | Loss: 0.4555 | Val AUC: 0.7296 | Val F1: 0.6496\n",
      "Epoch 030 | Loss: 0.4259 | Val AUC: 0.7277 | Val F1: 0.6530\n",
      "Epoch 040 | Loss: 0.4035 | Val AUC: 0.7343 | Val F1: 0.6593\n",
      "Epoch 050 | Loss: 0.3738 | Val AUC: 0.7183 | Val F1: 0.6570\n",
      "Epoch 060 | Loss: 0.3361 | Val AUC: 0.7119 | Val F1: 0.6563\n",
      "Epoch 070 | Loss: 0.2871 | Val AUC: 0.7051 | Val F1: 0.6550\n",
      "Epoch 080 | Loss: 0.2457 | Val AUC: 0.7062 | Val F1: 0.6554\n",
      "Epoch 090 | Loss: 0.2127 | Val AUC: 0.7048 | Val F1: 0.6582\n",
      "Epoch 100 | Loss: 0.1843 | Val AUC: 0.7110 | Val F1: 0.6683\n",
      "\n",
      "Test AUC: 0.7088 | Test Accuracy: 0.6401 | Test F1: 0.6716 | Test PR AUC: 0.7680\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "# 1. GNN Encoder + Dot Product Decoder\n",
    "class GCNLinkPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        # Dot product decoder\n",
    "        src, dst = edge_label_index\n",
    "        return (z[src] * z[dst]).sum(dim=1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_label_index):\n",
    "        z = self.encode(x, edge_index)\n",
    "        logits = self.decode(z, edge_label_index)\n",
    "        return logits\n",
    "\n",
    "# 2. Prepare data splits (already done with RandomLinkSplit)\n",
    "# train_data, val_data, test_data = transform(data)\n",
    "\n",
    "# 3. Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCNLinkPredictor(in_channels=train_data.x.size(1), hidden_channels=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(\n",
    "        train_data.x.to(device),\n",
    "        train_data.edge_index.to(device),\n",
    "        train_data.edge_label_index.to(device)\n",
    "    )\n",
    "    loss = loss_fn(out, train_data.edge_label.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    logits = model(\n",
    "        data.x.to(device),\n",
    "        data.edge_index.to(device),\n",
    "        data.edge_label_index.to(device)\n",
    "    )\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    labels = data.edge_label.cpu().numpy()\n",
    "    auc_score = roc_auc_score(labels, probs)\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    precision, recall, _ = precision_recall_curve(labels, probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return auc_score, acc, f1, pr_auc\n",
    "\n",
    "# 4. Training loop\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        val_auc, val_acc, val_f1, val_pr_auc = test(val_data)\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "# 5. Final evaluation\n",
    "test_auc, test_acc, test_f1, test_pr_auc = test(test_data)\n",
    "print(f\"\\nTest AUC: {test_auc:.4f} | Test Accuracy: {test_acc:.4f} | Test F1: {test_f1:.4f} | Test PR AUC: {test_pr_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
